# LLM Action Conversational App

A Python application that engages in a conversational loop with the user. For each prompt, it uses an LLM to generate Python code, saves it to a file, and executes it. The conversation maintains full history, allowing the LLM to reference previous exchanges.

## Prerequisites

- Python 3.x
- Ollama installed and running (see top-level README for setup)

## Setup

1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

## Usage

Run the application:
```bash
python app.py
```

Example conversation:
```
You: Give me the current time in San Francisco
[Code is generated and executed]

You: Now show me Tokyo
[Code is generated and executed, with awareness of previous context]

You: exit
```

## Exit Commands

Type any of the following to end the conversation:
- `exit`
- `quit`

## Safety Note

⚠️ **Warning**: This application executes code generated by an LLM. Only use with trusted prompts and be aware of potential security risks.

## Changing Models

In `app.py`, you can change the model by modifying the `model` parameter in the `ollama.chat()` call. For example:
- `'codellama:7b'` (current)
- `'codellama:13b'`
- `'llama2'`
- Any other model you have installed

